{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b09dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = 'reverse_image_search.csv'  # Replace with your dataset path\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Load the CLIP model and processor\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c87bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    image_path = row['path']  # Assuming the path is in a column named 'path'\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    image_features = model.get_image_features(**inputs)\n",
    "    # Ensure the tensor is detached from the computational graph before converting\n",
    "    embeddings.append(image_features.squeeze(0).detach().numpy().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e21741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "\n",
    "# Milvus parameters\n",
    "HOST = '127.0.0.1'\n",
    "PORT = '19530'\n",
    "TOPK = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae8ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(host=HOST, port=PORT)\n",
    "dim = 512  # Dimension of the embeddings\n",
    "METRIC_TYPE = 'L2'  # You can choose 'L2', 'IP', etc., based on your requirement\n",
    "INDEX_TYPE = 'IVF_FLAT'  # Index type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a2f7c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_collection_id_1',\n",
       " 'user_collection_id_3',\n",
       " 'transformers',\n",
       " 'image_based_search',\n",
       " 'image_based_search_transformers',\n",
       " 'text_based_search',\n",
       " 'user_collection_id_2']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f9ca2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_milvus_collection(collection_name):\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "    \n",
    "    fields = [\n",
    "        FieldSchema(name='path', dtype=DataType.VARCHAR, description='path to image', max_length=500, \n",
    "                    is_primary=True, auto_id=False),\n",
    "        FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, description='image embedding vectors', dim=dim)\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description='reverse image search')\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "    index_params = {\n",
    "        'metric_type': METRIC_TYPE,\n",
    "        'index_type': INDEX_TYPE,\n",
    "        'params': {\"nlist\": dim}\n",
    "    }\n",
    "    collection.create_index(field_name='embedding', index_params=index_params)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03891e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids= [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35857315",
   "metadata": {},
   "outputs": [],
   "source": [
    "for userId in user_ids:    \n",
    "    collection_name = 'user_collection_id_'+ (str)(userId)\n",
    "    collection = create_milvus_collection(collection_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5de17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = create_milvus_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6abcf6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_collection_id_1',\n",
       " 'user_collection_id_3',\n",
       " 'transformers',\n",
       " 'image_based_search',\n",
       " 'image_based_search_transformers',\n",
       " 'text_based_search',\n",
       " 'user_collection_id_2']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3e5099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility.drop_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d67803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:milvus]",
   "language": "python",
   "name": "conda-env-milvus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
