{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4423705d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./train/brain_coral/n01917289_1783.JPEG</td>\n",
       "      <td>brain_coral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./train/brain_coral/n01917289_4317.JPEG</td>\n",
       "      <td>brain_coral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>./train/brain_coral/n01917289_765.JPEG</td>\n",
       "      <td>brain_coral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>./train/brain_coral/n01917289_1079.JPEG</td>\n",
       "      <td>brain_coral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>./train/brain_coral/n01917289_2484.JPEG</td>\n",
       "      <td>brain_coral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                     path        label\n",
       "0   0  ./train/brain_coral/n01917289_1783.JPEG  brain_coral\n",
       "1   1  ./train/brain_coral/n01917289_4317.JPEG  brain_coral\n",
       "2   2   ./train/brain_coral/n01917289_765.JPEG  brain_coral\n",
       "3   3  ./train/brain_coral/n01917289_1079.JPEG  brain_coral\n",
       "4   4  ./train/brain_coral/n01917289_2484.JPEG  brain_coral"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../reverse_image_search.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f34204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "from towhee.types.image import Image\n",
    "\n",
    "id_img = df.set_index('id')['path'].to_dict()\n",
    "def read_images(results):\n",
    "    imgs = []\n",
    "    for re in results:\n",
    "        path = id_img[re.id]\n",
    "        imgs.append(Image(cv2.imread(path), 'BGR'))\n",
    "    return imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fff5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "\n",
    "def create_milvus_collection(collection_name, dim):\n",
    "    connections.connect(host='127.0.0.1', port='19530')\n",
    "    \n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "    \n",
    "    fields = [\n",
    "    FieldSchema(name='path', dtype=DataType.VARCHAR, description='path to image', max_length=500, \n",
    "                    is_primary=True, auto_id=False),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, description='embedding vectors', dim=dim)\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description='text image search')\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "    # create IVF_FLAT index for collection.\n",
    "    index_params = {\n",
    "        'metric_type':'L2',\n",
    "        'index_type':\"IVF_FLAT\",\n",
    "        'params':{\"nlist\":512}\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    return collection\n",
    "\n",
    "#collection = create_milvus_collection('text_image_search', 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4090e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection, utility\n",
    "connections.connect(host='127.0.0.1', port='19530')\n",
    "\n",
    "collection = create_milvus_collection('text_image_search', 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ea71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from towhee import ops, pipe, DataCollection\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596502f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[ WARN:0@24.198] global loadsave.cpp:248 findDecoder imread_('./teddy.png'): can't open/read file: check file path/integrity\n",
      "2024-03-31 13:12:07,680 - 126739130873408 - image_decode_cv2.py-image_decode_cv2:68 - ERROR: Read image ./teddy.png failed\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Node-image-decode/cv2-0 runs failed, error msg: Read image ./teddy.png failed, Traceback (most recent call last):\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/nodes/node.py\", line 158, in _call\n    return True, self._op(*inputs), None\n                 ^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-decode/cv2/versions/main/image_decode_cv2.py\", line 69, in __call__\n    raise RuntimeError(err)\nRuntimeError: Read image ./teddy.png failed\n, Traceback (most recent call last):\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/nodes/node.py\", line 171, in process\n    self.process_step()\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/nodes/_map.py\", line 63, in process_step\n    assert succ, msg\nAssertionError: Read image ./teddy.png failed, Traceback (most recent call last):\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/nodes/node.py\", line 158, in _call\n    return True, self._op(*inputs), None\n                 ^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-decode/cv2/versions/main/image_decode_cv2.py\", line 69, in __call__\n    raise RuntimeError(err)\nRuntimeError: Read image ./teddy.png failed\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m p \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     pipe\u001b[38;5;241m.\u001b[39minput(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m, ops\u001b[38;5;241m.\u001b[39mimage_decode\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39moutput(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvec\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m DataCollection(p(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./teddy.png\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/runtime_pipeline.py:159\u001b[0m, in \u001b[0;36mRuntimePipeline.__call__\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs):\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Output with ordering matching the input `DataQueue`.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39minputs, profiler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, tracer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/runtime_pipeline.py:177\u001b[0m, in \u001b[0;36mRuntimePipeline._call\u001b[0;34m(self, profiler, tracer, trace_edges, *inputs)\u001b[0m\n\u001b[1;32m    174\u001b[0m time_profiler \u001b[38;5;241m=\u001b[39m TimeProfiler(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m profiler \u001b[38;5;28;01melse\u001b[39;00m TimeProfiler(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m graph \u001b[38;5;241m=\u001b[39m _Graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dag_repr\u001b[38;5;241m.\u001b[39mnodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dag_repr\u001b[38;5;241m.\u001b[39medges, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operator_pool, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_pool, time_profiler, trace_edges)\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph(inputs), [graph\u001b[38;5;241m.\u001b[39mtime_profiler] \u001b[38;5;28;01mif\u001b[39;00m profiler \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, [graph\u001b[38;5;241m.\u001b[39mdata_queues] \u001b[38;5;28;01mif\u001b[39;00m tracer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/runtime_pipeline.py:116\u001b[0m, in \u001b[0;36m_Graph.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Union[Tuple, List]):\n\u001b[1;32m    115\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_call(inputs)\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m~/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/runtime_pipeline.py:34\u001b[0m, in \u001b[0;36m_GraphResult.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 34\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mrelease_op()\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\n",
      "File \u001b[0;32m~/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/runtime_pipeline.py:95\u001b[0m, in \u001b[0;36m_Graph.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m             errs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39merr_msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errs:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(errs)\n\u001b[1;32m     96\u001b[0m end_edge_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_output\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mout_edges[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     97\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queues[end_edge_num]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Node-image-decode/cv2-0 runs failed, error msg: Read image ./teddy.png failed, Traceback (most recent call last):\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/nodes/node.py\", line 158, in _call\n    return True, self._op(*inputs), None\n                 ^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-decode/cv2/versions/main/image_decode_cv2.py\", line 69, in __call__\n    raise RuntimeError(err)\nRuntimeError: Read image ./teddy.png failed\n, Traceback (most recent call last):\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/nodes/node.py\", line 171, in process\n    self.process_step()\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/nodes/_map.py\", line 63, in process_step\n    assert succ, msg\nAssertionError: Read image ./teddy.png failed, Traceback (most recent call last):\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/nodes/node.py\", line 158, in _call\n    return True, self._op(*inputs), None\n                 ^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-decode/cv2/versions/main/image_decode_cv2.py\", line 69, in __call__\n    raise RuntimeError(err)\nRuntimeError: Read image ./teddy.png failed\n\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "p = (\n",
    "    pipe.input('path')\n",
    "    .map('path', 'img', ops.image_decode.cv2('rgb'))\n",
    "    .map('img', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image'))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .output('img', 'vec')\n",
    ")\n",
    "\n",
    "DataCollection(p('./teddy.png')).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e573e9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse;\"><tr><th style=\"text-align: center; font-size: 130%; border: none;\">text</th> <th style=\"text-align: center; font-size: 130%; border: none;\">vec</th></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">cat</td><td style=\"text-align: left; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[0.033149168, -0.020378174, 0.000116232535, ...] shape=(512,)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "p2 = (\n",
    "    pipe.input('text')\n",
    "    .map('text', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='text'))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .output('text', 'vec')\n",
    ")\n",
    "\n",
    "DataCollection(p2(\"cat\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e807a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = DataCollection(p2(\"A teddybear on a skateboard in Times Square.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b839f96c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Node-image-text-embedding/clip-2 runs failed, error msg: Create image-text-embedding/clip-2 operator image-text-embedding/clip:main with args None and kws {'model_name': 'clip_vit_base_patch16', 'modality': 'image', 'device': 0} failed, err: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx, Traceback (most recent call last):\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/nodes/node.py\", line 88, in initialize\n    self._op = self._op_pool.acquire_op(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/operator_manager/operator_pool.py\", line 106, in acquire_op\n    op = self._op_loader.load_operator(hub_op_id, op_args, op_kws, tag, latest)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/operator_manager/operator_loader.py\", line 154, in load_operator\n    op = factory(function, arg, kws, tag, latest)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/operator_manager/operator_loader.py\", line 137, in _load_operator_from_hub\n    return self._load_operator_from_path(path, function, arg, kws, tag)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/operator_manager/operator_loader.py\", line 125, in _load_operator_from_path\n    return self._instance_operator(op, arg, kws) if op is not None else None\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/operator_manager/operator_loader.py\", line 163, in _instance_operator\n    return op(*arg, **kws) if kws is not None else op(*arg)\n           ^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-text-embedding/clip/versions/main/__init__.py\", line 19, in clip\n    return Clip(model_name, modality, device, checkpoint_path)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-text-embedding/clip/versions/main/clip.py\", line 106, in __init__\n    self.model = Model(real_name, modality, checkpoint_path, device)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/runtime_conf.py\", line 88, in _decorated\n    return model(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-text-embedding/clip/versions/main/clip.py\", line 77, in __init__\n    self.model = create_model(model_name, modality, checkpoint_path, device)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-text-embedding/clip/versions/main/clip.py\", line 45, in create_model\n    hf_clip_model.to(device)\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 2556, in to\n    return super().to(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1152, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n    module._apply(fn)\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n    module._apply(fn)\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n    module._apply(fn)\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 825, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1150, in convert\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 302, in _lazy_init\n    torch._C._cuda_init()\nRuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:17\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/pipeline.py:101\u001b[0m, in \u001b[0;36mPipeline.output\u001b[0;34m(self, *output_schema)\u001b[0m\n\u001b[1;32m     98\u001b[0m dag_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clo_node][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(uid)\n\u001b[1;32m    100\u001b[0m run_pipe \u001b[38;5;241m=\u001b[39m RuntimePipeline(dag_dict)\n\u001b[0;32m--> 101\u001b[0m run_pipe\u001b[38;5;241m.\u001b[39mpreload()\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_pipe\n",
      "File \u001b[0;32m~/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/runtime_pipeline.py:153\u001b[0m, in \u001b[0;36mRuntimePipeline.preload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreload\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    150\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m    Preload the operators.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _Graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dag_repr\u001b[38;5;241m.\u001b[39mnodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dag_repr\u001b[38;5;241m.\u001b[39medges, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operator_pool, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread_pool, TimeProfiler(\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/runtime_pipeline.py:67\u001b[0m, in \u001b[0;36m_Graph.__init__\u001b[0;34m(self, nodes, edges, operator_pool, thread_pool, time_profiler, trace_edges)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_profiler\u001b[38;5;241m.\u001b[39mrecord(Event\u001b[38;5;241m.\u001b[39mpipe_name, Event\u001b[38;5;241m.\u001b[39mpipe_in)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_queue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queues[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/runtime_pipeline.py:83\u001b[0m, in \u001b[0;36m_Graph._initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m node \u001b[38;5;241m=\u001b[39m create_node(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes[name], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operator_pool, in_queues, out_queues, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_profiler)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node\u001b[38;5;241m.\u001b[39minitialize():\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(node\u001b[38;5;241m.\u001b[39merr_msg)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node_runners\u001b[38;5;241m.\u001b[39mappend(node)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Node-image-text-embedding/clip-2 runs failed, error msg: Create image-text-embedding/clip-2 operator image-text-embedding/clip:main with args None and kws {'model_name': 'clip_vit_base_patch16', 'modality': 'image', 'device': 0} failed, err: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx, Traceback (most recent call last):\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/nodes/node.py\", line 88, in initialize\n    self._op = self._op_pool.acquire_op(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/operator_manager/operator_pool.py\", line 106, in acquire_op\n    op = self._op_loader.load_operator(hub_op_id, op_args, op_kws, tag, latest)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/operator_manager/operator_loader.py\", line 154, in load_operator\n    op = factory(function, arg, kws, tag, latest)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/operator_manager/operator_loader.py\", line 137, in _load_operator_from_hub\n    return self._load_operator_from_path(path, function, arg, kws, tag)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/operator_manager/operator_loader.py\", line 125, in _load_operator_from_path\n    return self._instance_operator(op, arg, kws) if op is not None else None\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/operator_manager/operator_loader.py\", line 163, in _instance_operator\n    return op(*arg, **kws) if kws is not None else op(*arg)\n           ^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-text-embedding/clip/versions/main/__init__.py\", line 19, in clip\n    return Clip(model_name, modality, device, checkpoint_path)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-text-embedding/clip/versions/main/clip.py\", line 106, in __init__\n    self.model = Model(real_name, modality, checkpoint_path, device)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/towhee/runtime/runtime_conf.py\", line 88, in _decorated\n    return model(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-text-embedding/clip/versions/main/clip.py\", line 77, in __init__\n    self.model = create_model(model_name, modality, checkpoint_path, device)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/.towhee/operators/image-text-embedding/clip/versions/main/clip.py\", line 45, in create_model\n    hf_clip_model.to(device)\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 2556, in to\n    return super().to(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1152, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n    module._apply(fn)\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n    module._apply(fn)\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n    module._apply(fn)\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 825, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1150, in convert\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/kasim/anaconda3/envs/milvus/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 302, in _lazy_init\n    torch._C._cuda_init()\nRuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "collection = create_milvus_collection('text_image_search', 512)\n",
    "\n",
    "def read_csv(csv_path, encoding='utf-8-sig'):\n",
    "    import csv\n",
    "    with open(csv_path, 'r', encoding=encoding) as f:\n",
    "        data = csv.DictReader(f)\n",
    "        for line in data:\n",
    "            yield int(line['id']), line['path']\n",
    "\n",
    "p3 = (\n",
    "    pipe.input('csv_file')\n",
    "    .flat_map('csv_file', ('id', 'path'), read_csv)\n",
    "    .map('path', 'img', ops.image_decode.cv2('rgb'))\n",
    "    .map('img', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch16', modality='image', device=0))\n",
    "    .map('vec', 'vec', lambda x: x / np.linalg.norm(x))\n",
    "    .map(('path', 'vec'), (), ops.ann_insert.milvus_client(host='127.0.0.1', port='19530', collection_name='text_image_search'))\n",
    "    .output()\n",
    ")\n",
    "\n",
    "ret = p3('reverse_image_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e889c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:milvus]",
   "language": "python",
   "name": "conda-env-milvus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
